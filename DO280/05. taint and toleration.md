## Prepare the lab for this question 1?
```
oc adm taint node $(oc get nodes | awk '{print $1}' | grep -v NAME) datacenter=delhi:NoSchedule
oc new-project chapter1
oc new-app --name webserver-app1 --image registry.ocp4.example.com:8443/redhattraining/hello-world-nginx:v1.0 
```


# Question 1. An application is running on the `chapter1` project. There is one pod running and your task is it must generate the output.

```
oc project chapter1
```
### Pre-Check, you must observe that pod is in the pending state.
```
oc get all
```
### Identify the nodes on which having issue.
```
oc get pods -o wide
```
### Check the events. 
```
oc event
```

```
3m14s                 Normal    ScalingReplicaSet   Deployment/webserver-app1              Scaled up replica set webserver-app1-c8995748c to 1
3m14s                 Normal    ScalingReplicaSet   Deployment/webserver-app1              Scaled up replica set webserver-app1-6bc4fdd7b6 to 1
3m14s                 Normal    SuccessfulCreate    ReplicaSet/webserver-app1-c8995748c    Created pod: webserver-app1-c8995748c-4cg5l
3m14s                 Warning   FailedScheduling    Pod/webserver-app1-c8995748c-4cg5l     0/1 nodes are available: 1 node(s) had **`untolerated taint`** {datacenter: delhi}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..
3m13s                 Warning   FailedCreate        ReplicaSet/webserver-app1-6bc4fdd7b6   Error creating: Pod "webserver-app1-6bc4fdd7b6-6kzn4" is invalid: spec.containers[0].image: Invalid value: " ": must not have leading or trailing whitespace
30s (x7 over 3m12s)   Warning   FailedCreate        ReplicaSet/webserver-app1-6bc4fdd7b6   (combined from similar events): Error creating: Pod "webserver-app1-6bc4fdd7b6-wvwzj" is invalid: spec.containers[0].image: Invalid value: " ": must not have leading or trailing whitespace


```
### If you observe the `untolerated taint` errror message, it means that taint is applied on nodes and you have to add the toleration on pod or remove the taint from the node.
```
oc describe node master01 | grep -i taint
```

## How to remove the taint from nodes? Please note that, if you have multiple nodes then you have to remove the taint from all the workernodes. 
```
oc adm taint node master01 datacenter-
```
### Post check.
```
oc get pods
```

#### See the below output only for your references.
```
[student@workstation ~]$ oc get pods
NAME                             READY   STATUS    RESTARTS   AGE
webserver-app1-c8995748c-4cg5l   0/1     Pending   0          6m44s

[student@workstation ~]$ oc describe node master01 | grep -i taint
Taints:             datacenter=delhi:NoSchedule

[student@workstation ~]$ oc adm taint node master01 datacenter-
node/master01 untainted

[student@workstation ~]$ oc describe node master01 | grep -i taint
Taints:             <none>

[student@workstation ~]$ oc get pods
NAME                             READY   STATUS    RESTARTS   AGE
webserver-app1-c8995748c-4cg5l   1/1     Running   0          9m48s
[student@workstation ~]$
```

### Check the service is created or not ?
```
oc get service
```

## If it is not created then create a new one.
```
oc expose service webserver-app1
```
### How to check ?
```
oc get svc,route
```
### Open the webiste. Either CLI or webportal.
```
curl ebserver-app1-chapter1.apps.ocp4.example.com  | head
```
---
## Prepare the lab for this question 2?
```
oc new-project chapter2
oc new-app --name webserver-app2 --image registry.ocp4.example.com:8443/redhattraining/hello-world-nginx:v1.0
oc expose service webserver-app2 
oc patch service webserver-app2 -n chapter2 --type=json -p='[{"op": "replace", "path": "/spec/selector/deployment", "value": "anishrana2001"}]'
```


# Question 2. An application is running on the `chapter2` project. There is one pod running and your task is it must generate the output.
---
### Solution
### Check the resources.
```
oc get all
```

### You may observe that pods is running. So, check the logs and event
```
oc logs pods/pod_name
```
```
oc events
```
### You may not observe any thing. So let's open the URL
```
oc get route
```
### For my lab, it is : webserver-app2-chapter2.apps.ocp4.example.com
```
http://webserver-app2-chapter2.apps.ocp4.example.com
```

### It should not work. It means that application inside the pod is working fine but we are not able to reach to pod.
### Check service.
```
oc describe service webserver-app2
```

```
[student@workstation ~]$ oc describe service webserver-app2 
Name:              webserver-app2
Namespace:         chapter2
Labels:            app=webserver-app2
                   app.kubernetes.io/component=webserver-app2
                   app.kubernetes.io/instance=webserver-app2
Annotations:       openshift.io/generated-by: OpenShiftNewApp
Selector:          deployment=anishrana2001      ### Check the label
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                172.30.127.45
IPs:               172.30.127.45
Port:              8080-tcp  8080/TCP
TargetPort:        8080/TCP
Endpoints:         <none>      ### End points are empty.
Session Affinity:  None
Events:            <none>
```
### One can notice that endpoints are missing. You need to update the label on service. Thus, check the Deployment's yaml file and look for `template.metadata.label`
### Deployment is working so we will not going to change the label of Deployment and service is not working, so we will modify the service label.
```
oc get deployment/deployment_name -o yaml 
```
### For your references.
```
  template:
    metadata:
      annotations:
        openshift.io/generated-by: OpenShiftNewApp
      creationTimestamp: null
      labels:
        deployment: webserver-app2   >>>>
    spec:
      containers:
      - image: registry.ocp4.example.com:8443/redhattraining/hello-world-nginx@sha256:6926d361b8e2f778f88341fbd0d231337c38d12c177fdacf2a677dc6b70a1f59
        imagePullPolicy: IfNotPresent
```
### Or you can use the "yq" command, to verify the labels
```
oc get deployment webserver-app2  -o yaml  | yq r - spec.template.metadata.labels
```

```
oc edit service/todo-svc
```

### See the reference image.
![image](https://github.com/user-attachments/assets/5c61faff-6404-440e-98a4-05f52d8bdae1)


### check the service again.
```
oc describe service webserver-app2
```

### You may not observe any thing. So let's open the URL
```
oc get route
```
### For my lab, it is : webserver-app2-chapter2.apps.ocp4.example.com
```
http://webserver-app2-chapter2.apps.ocp4.example.com
```

---
## Prepare the lab for this question 3?
```
oc new-project chapter3

cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
  labels:
    app: webserver-app3
    app.kubernetes.io/component: webserver-app3
    app.kubernetes.io/instance: webserver-app3
  name: webserver-app3
  namespace: chapter3
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      deployment: webserver-app3
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/restartedAt: "2025-05-13T03:57:01-04:00"
        openshift.io/generated-by: OpenShiftNewApp
      labels:
        deployment: webserver-app3
    spec:
      containers:
      - image: registry.ocp4.example.com:8443/redhattraining/hello-world-nginx@sha256:6926d361b8e2f778f88341fbd0d231337c38d12c177fdacf2a677dc6b70a1f59
        imagePullPolicy: IfNotPresent
        name: webserver-app3
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      nodeSelector:
        disktype: ssd
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
EOF
oc expose deployment/webserver-app3
oc expose service webserver-app3


```


# Question 3. An application is running on the `chapter3` project. There is one pod, which is in pending state. Your task is it must generate the output.
---
### Solution
### Check the resources.
## Got to the project
```
oc project chaper3
```

```
oc get all
```
### Check the logs of pod.
```
oc log pod/PODNAME
```

## Check the events.
```
oc event
```
### From the above output, it is clear that, we have issue due to to `nodeSelector`.

### Check the nodeSelector value in the deployment
```
oc get deployment/webserver-app3 -o yaml | grep -iA 5 selector
```

### Check the label on nodes. Please note that I have 1 node, so I am checking label on 1 node only. If  you have multiple, then you need to check the label on all nodes.
```
oc describe nodes master01  | grep -iA 5 label
```

### Please note that, I am adding label on 1 node only. If  you have multiple nodes, then you need to add the label on all nodes.
```
oc label nodes master01 disktype=ssd
```

### Check the label again on node.
```
oc describe nodes master01  | grep -iA 5 label
```

### Post checks!!
```
oc get pods
```


## Check the route.
```
oc get route
```
### Copy the URL and paste into the webbrowser.

### Below are for your references.
```
[student@workstation ~]$ oc event
5m8s        Normal    Killing                  Pod/webserver-app3-7b4bd5c879-lhwjk    Stopping container webserver-app3
5m8s        Warning   FailedScheduling         Pod/webserver-app3-5946c66dc4-pxq87    skip schedule deleting pod: chapter3/webserver-app3-5946c66dc4-pxq87
4m53s       Normal    SuccessfulCreate         ReplicaSet/webserver-app3-5946c66dc4   Created pod: webserver-app3-5946c66dc4-rvsz5
4m53s       Normal    ScalingReplicaSet        Deployment/webserver-app3              Scaled up replica set webserver-app3-5946c66dc4 to 1
4m53s       Warning   FailedScheduling         Pod/webserver-app3-5946c66dc4-rvsz5    **0/1 nodes are available: 1 node(s) didn't match Pod's node `affinity/selector`. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..**


[student@workstation ~]$ oc get deployment/webserver-app3 -o yaml | grep -iA 5 selector
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"webserver-app3","app.kubernetes.io/component":"webserver-app3","app.kubernetes.io/instance":"webserver-app3"},"name":"webserver-app3","namespace":"chapter3"},"spec":{"progressDeadlineSeconds":600,"replicas":1,"revisionHistoryLimit":10,"selector":{"matchLabels":{"deployment":"webserver-app3"}},"strategy":{"rollingUpdate":{"maxSurge":"25%","maxUnavailable":"25%"},"type":"RollingUpdate"},"template":{"metadata":{"annotations":{"kubectl.kubernetes.io/restartedAt":"2025-05-13T03:57:01-04:00","openshift.io/generated-by":"OpenShiftNewApp"},"labels":{"deployment":"webserver-app3"}},"spec":{"containers":[{"image":"registry.ocp4.example.com:8443/redhattraining/hello-world-nginx@sha256:6926d361b8e2f778f88341fbd0d231337c38d12c177fdacf2a677dc6b70a1f59","imagePullPolicy":"IfNotPresent","name":"webserver-app3","ports":[{"containerPort":8080,"protocol":"TCP"}],"resources":{},"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File"}],"dnsPolicy":"ClusterFirst","nodeSelector":{"disktype":"ssd"},"restartPolicy":"Always","schedulerName":"default-scheduler","securityContext":{},"terminationGracePeriodSeconds":30}}}}
  creationTimestamp: "2025-05-13T08:03:49Z"
  generation: 1
  labels:
    app: webserver-app3
    app.kubernetes.io/component: webserver-app3
--
  selector:
    matchLabels:
      deployment: webserver-app3
  strategy:
    rollingUpdate:
      maxSurge: 25%
--
      nodeSelector:            ### 👈👈👈
        disktype: ssd          ### 👈👈👈
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30

[student@workstation ~]$ oc describe nodes master01  | grep -i label
Labels:             beta.kubernetes.io/arch=amd64

[student@workstation ~]$ oc label nodes master01 disktype=ssd
node/master01 labeled

[student@workstation ~]$ oc describe nodes master01  | grep -iA 5 label
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    disktype=ssd    ### 👈👈👈
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=master01
                    kubernetes.io/os=linux
[student@workstation ~]$ oc get pods
NAME                              READY   STATUS    RESTARTS   AGE
webserver-app3-5946c66dc4-rvsz5   1/1     Running   0          6m30s
[student@workstation ~]$ 

```


### Prepare for Question 4.
```
oc new-project chapter4
oc adm taint node $(oc get nodes | awk '{print $1}' | grep -v NAME) datacenter=delhi:NoSchedule
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
  labels:
    app: webserver-app4
    app.kubernetes.io/component: webserver-app4
    app.kubernetes.io/instance: webserver-app4
  name: webserver-app4
  namespace: chapter4
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      deployment: webserver-app4
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/restartedAt: "2025-05-13T03:57:01-04:00"
        openshift.io/generated-by: OpenShiftNewApp
      labels:
        deployment: webserver-app4
    spec:
      containers:
      - image: registry.ocp4.example.com:8443/redhattraining/hello-world-nginx@sha256:6926d361b8e2f778f88341fbd0d231337c38d12c177fdacf2a677dc6b70a1f59
        imagePullPolicy: IfNotPresent
        name: webserver-app4
        ports:
        - containerPort: 8080
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      nodeSelector:
        disktype: ssd
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
EOF
oc expose deployment/webserver-app4
oc expose service webserver-app4
oc patch service webserver-app4 -n chapter4 --type=json -p='[{"op": "replace", "path": "/spec/selector/deployment", "value": "anishrana2001"}]'
```
### Do it by yourself.


# Question 5. An application is running on the chapter5 project. There is one pod, which is in pending state. Your task is it must generate the output.

### Prepare the lab for question 5.
```
oc login -u admin -p redhatocp https://api.ocp4.example.com:6443
oc new-project chapter5
oc new-app --name webserver-app5 --image registry.ocp4.example.com:8443/redhattraining/hello-world-nginx:v1.0

oc patch deployment webserver-app5 -p '{"spec": {"template": {"spec": {"containers": [{"name": "webserver-app5", "resources": {"limits": {"cpu": "2", "memory": "18Gi"}}}]}}}}'
oc delete replicasets.apps $(oc get replicasets.apps | awk '$4~ /1/ {print $1}')
```

## Solution.

## Go to the project first. 
```
oc project chapter5
```
```
oc get all
```
## You observe pod is in pending state. 
## Check the events. 
```
oc get events --sort-by='.lastTimestamp' | tail
```

## From the output, you get to know that there is some issue with CPU or Memory. Both are part of `resources`. Remember this keyword.
### Check the deployment.
```
oc get deployment/webserver-app5 -o yaml | grep -iA 5 resources
```

### Edite the Deployment and modify the memory to 300Mi 
```
oc edit deployment/webserver-app5
```

### Execute the below command again.
```
oc get deployment/webserver-app5 -o yaml | grep -iA 5 resources
```

### Check the pods.
```
oc get all
```

### Expose the service.
```
oc expose  service webserver-app5
```

### Check the route.
```
oc get route
```
### Finally, Post checks.....
```
curl webserver-app5-chapter5.apps.ocp4.example.com | head
```


## How to clear the Lab?
```
oc delete project chapter1
oc delete project chapter2
oc delete project chapter3
oc delete project chapter4
oc delete project chapter5
```
